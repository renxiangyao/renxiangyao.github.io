<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World!</title>
    <url>/2020/08/07/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://renxiangyao.github.io/">my blog</a>! </p>
<p>Thanks to <a href="https://hexo.io/">Hexo</a>, I have recently re-built my personal website using Hexo framework and find the whole process fast and simple. There seems to be a lot of powerful features in this framework and I will try to explore them in the near future.</p>
<p>Because of the good experience, hence personally I highly recommend using Hexo if you want to build your own personal website on GitHub Pages, although it is not officially supported by GitHub (unlike [Jekyll]). I will try to write some blog posts on how to setup a person website using Hexo + GitHub Pages. At the moment, if you got any questions, you can ask me on my <a href="mailto:renxiangyao@gmail.com">Email</a>.</p>
<p>This is a testing post. Just to have a go on blog writing with some code sample test. </p>
<h2 id="Some-code-sample-test"><a href="#Some-code-sample-test" class="headerlink" title="Some code sample test"></a>Some code sample test</h2><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;C:/Python/data/test.csv&#x27;</span>, header=<span class="number">0</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="R"><a href="#R" class="headerlink" title="R"></a>R</h3><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line"><span class="keyword">library</span>(tidyverse)</span><br><span class="line"><span class="keyword">library</span>(forecast)</span><br><span class="line">df&lt;-read.csv(<span class="string">&quot;C:/R/data/test.csv&quot;</span>,header=<span class="literal">TRUE</span>, sep=<span class="string">&quot;,&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="SAS"><a href="#SAS" class="headerlink" title="SAS"></a>SAS</h3><figure class="highlight sas"><table><tr><td class="code"><pre><span class="line"><span class="meta">libname</span> data <span class="string">&quot;C:\SAS\data&quot;</span>;</span><br><span class="line"><span class="keyword">data </span>work.test1;</span><br><span class="line"><span class="meta">set</span> data.testdata;</span><br><span class="line"><span class="keyword">run;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>blog testing</tag>
      </tags>
  </entry>
  <entry>
    <title>A brief introduction to XGBoost, LightGBM, CatBoost</title>
    <url>/2020/08/14/A-brief-introduction-to-XGBoost-LightGBM-CatBoost/</url>
    <content><![CDATA[<p><img src="/images/car_race.jpg" alt="car_race"><br>Recently I tried out using <strong>CatBoost</strong> to carry out a machine learning prediction, and found it very useful and convenient. It has unique features and strengths comparing to the other very popular Boosting Machine ML (Machine Learning) algorithms like XGBoost, LightGBM, etc. Hence, I think writing a blog to briefly introduce and summarise these popularly used Boosting Machines ML (Machine Learning) algorithms would be handy. Some of the statements are based on my own understanding and experiences and may be biased.</p>
<h1 id="Boosting-in-Ensemble-Learning"><a href="#Boosting-in-Ensemble-Learning" class="headerlink" title="Boosting in Ensemble Learning"></a>Boosting in Ensemble Learning</h1><p>To understand Boosting, we use the structure below to better illustrate the idea:</p>
<ul>
<li>Ensemble Learning    <ul>
<li>Bagging</li>
<li>Boosting<ul>
<li>GBM</li>
<li>XGBoost</li>
<li>LightGBM</li>
<li>CatBoost</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>What is an Ensemble Learning? As the word “Ensemble” reveals, it is a concept of collective intelligence. Instead of using only one machine learning model to predict the target, Ensemble learning combines multiple ML models, and gives an aggregated prediction from several models.</p>
<a id="more"></a>
<p>Bagging and Boosting are 2 widely used Ensemble Learning methods. In short, Bagging split the training dataset into multiple datasets, then build machine learning models (usually decision tree model) on each splited dataset, then aggregated the output to provide a single prediction on the target. In Boosting, the models are built sequetially where each subsequent decision tree model aims to reduce the errors of previous decision tree model. Subsequent models are based on previous model, then the final model take the weighted mean of previous models. I will write blogs to dig more deeply into Bagging and Boosting Ensemble Learning methods.</p>
<p><img src="/images/bagging_vs_boosting.jpg" alt="bagging_vs_boosting"></p>
<center class="image-caption">Ensemble Learning: Bagging vs Boosting <a href="https://www.pluralsight.com/guides/ensemble-methods:-bagging-versus-boosting">[Source]</a></center>

<h1 id="GBM-Gradient-Boosting-Machine"><a href="#GBM-Gradient-Boosting-Machine" class="headerlink" title="GBM (Gradient Boosting Machine)"></a>GBM (Gradient Boosting Machine)</h1><p>The prediction improves iteratively in Boosting. When we build the subsequent model, How do we find the direction to reduce the prediction error of preivous decision tree model fastly? GBM (Gradient Boosting) use Gradient Descent method to optimize the Loss function (function defined on prediction error) to find the direction of next iteration. Hence comes the name of Gradient Boosting.</p>
<p><img src="/images/gbm.png" alt="GBM"></p>
<center class="image-caption">Gradient Boosting <a href="https://bradleyboehmke.github.io/HOML/gbm.html#fig:sequential-fig">[Source]</a></center>

<h1 id="XGBoost-Extreme-Gradient-Boosting-Machine"><a href="#XGBoost-Extreme-Gradient-Boosting-Machine" class="headerlink" title="XGBoost (Extreme Gradient Boosting Machine)"></a><a href="https://xgboost.readthedocs.io/en/latest/">XGBoost</a> (Extreme Gradient Boosting Machine)</h1><p>As the name “Extreme” suggests, XGBoost is an advanced implementation of GBM. Although the concept are similar to GBM, but the algorithm and implementation when carring out the calculations are hugely improved and well-engineered. XGBoost has proved to be a very effective and powerful ML algorithm, extensively used in ML competitions and hackathons, like Kaggle etc, and won great reputations (<a href="https://atlas.cern/updates/atlas-news/machine-learning-wins-higgs-challenge">one example</a>). XGBoost initially started as a research project by <a href="https://tqchen.com/"><strong>Tianqi Chen</strong></a>. Over the years since 2014, XGBoost has growed a large community of users, hence providing great support if you want to implement advanced features. The most important 2 unique features of XGBoost compare to GBM is <strong>Regularization</strong> and <strong>Parallel Processing</strong>. XGBoost includes a variety of regularization which prevents overfitting and improves overall performance. And XGBoost can make use of multiple cores of CPUs and GPUs to achieve faster computing, significantly reduces training time.</p>
<h1 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a><a href="https://lightgbm.readthedocs.io/en/latest/">LightGBM</a></h1><p><strong>Microsoft</strong> released 1st stable version of LightGBM (often in short LGBM) in Jan 2017. Hence it has relatively smaller community, but it starts to catch great attention in recent years (<a href="https://www.kaggle.com/shixw125/1st-place-lgb-model-public-0-506-private-0-511">Example</a>: <em>Kaggle Corporación Favorita Grocery Sales Forecasting Competition 1st place solution</em>) because it beats the other Gradient Boosting algorithms when the dataset is extremely large, but it does <em>not</em> work well on small datasets. This unique feature is because LightGBM has adopted a very special “leaf-wise” tree growth method. We will not go into technical details here, but due to this “leaf-wise” tree growth strategy, when facing extremely large datasets, it can achieve much better accuracy and faster speed that other algorithms hard to achieve. Hence the word “Light”. But it is also a “Double-edged sword”, also because of this, it is not able to work well with small datasets since overfitting can happen with this “leaf-wise” tree growth strategy.</p>
<p><img src="/images/xgboost_vs_lgbm.png" alt="xgboost_vs_lgbm"></p>
<center class="image-caption">XGBoost vs LightGBM: Tree Growth <a href="https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/?utm_source=blog&utm_medium=4-boosting-algorithms-machine-learning">[Source]</a></center>

<h1 id="CatBoost"><a href="#CatBoost" class="headerlink" title="CatBoost"></a><a href="https://catboost.ai/">CatBoost</a></h1><p>CatBoost is relatively new. I think its 1st debut was around 2017 developed by <strong>Yandex</strong> (a company like Google search in Russia). Just like XGBoost and LGBM, It is an Open-Source ML libary for Gradient Boosting on Decision Trees. The unique feature of CatBoost is automatically handling Categorical features. Hnadling categorical variables can be a tedious process, especially when you have a large number of categorical variables. When the categorical variables have a lot of levels, performing one-hot-encoding (the method to transform categorical variable to numerical variable) will increase the dimensionality exponentially, and the dataset can become really chanllenging to work with. Hence, CatBoost automatically deal with categorical variables effectively can provide great ease of use when you have to deal with mulptile categories of data, such as Audio, Text, Image, etc.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>I have summarised some key features of XGBoost, LGBM, and CatBoost algorithms in the table below. In my opinion, there is no universal best model in all scenarios. Each model got its own strengths and unique features and hence will be case by case basis.</p>
<table>
<thead>
<tr>
<th>Features</th>
<th>XGBoost</th>
<th>LightGBM</th>
<th>CatBoost</th>
</tr>
</thead>
<tbody><tr>
<td>Ease of Use</td>
<td>Easy to use</td>
<td>Easy to use</td>
<td>Easy to use</td>
</tr>
<tr>
<td>Community Support</td>
<td>Relatively large community</td>
<td>Still new, relatively small community</td>
<td>Still new, relatively small community</td>
</tr>
<tr>
<td>Speed</td>
<td>Fast</td>
<td>Very Fast</td>
<td>Fast</td>
</tr>
<tr>
<td>Data size</td>
<td>Works well for both large and small dataset</td>
<td>Works well for extremely large dataset Does <em>not</em> work well on small dataset</td>
<td>Works well for both large and small dataset</td>
</tr>
<tr>
<td>Parallel Processing</td>
<td>Supported</td>
<td>Supported</td>
<td>Supported</td>
</tr>
<tr>
<td>Missing Value Handling</td>
<td>Automaticaly</td>
<td>Automaticaly</td>
<td>Automaticaly</td>
</tr>
<tr>
<td>Categorical Features Handling</td>
<td>Manually pre-processing</td>
<td>Limited</td>
<td>Automaticaly</td>
</tr>
<tr>
<td>Tree Growth</td>
<td>Splits up to the specified max_depth hyperparameter and then starts pruning the tree backwards</td>
<td>leaf-wise tree growth</td>
<td>grows a balanced tree</td>
</tr>
<tr>
<td>Split method</td>
<td>Not using any weighted sampling techniques, which makes split process slower</td>
<td>Supports Gradient-based One-side Sampling (GOSS) which speed up the split process</td>
<td>Offers Minimal Variance Sampling (MVS) which speed up the split process</td>
</tr>
</tbody></table>
<p>That’s all for now! Hope it will be useful. Next I plan to write a blog on implementing CatBoost to solve a classification problem with code examples. Stay tuned!</p>
<p>Until next time, Take care.</p>
]]></content>
      <categories>
        <category>Intro and Summary</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>XGBoost</tag>
        <tag>LightGBM</tag>
        <tag>CatBoost</tag>
      </tags>
  </entry>
  <entry>
    <title>A Draft of Retail Analytics Framework (v1.0) - with specific case study in Supermarket and Grocery Industry</title>
    <url>/2020/10/10/A-Supermarket-Analytics-Framework/</url>
    <content><![CDATA[<p><img src="/images/retail_analytics_framework_v1.0.png" alt="retail_analytics_framework_v1.0"><br>New Zealand retail industry has been growing steadily over last decade post 2008 GFC (Global Finacial Crisis). COVID-19 has caused significant impact on New Zealand retail industry, as retail shops and stores had to close, people were not moving, there was no traffic on the road during lock-down. The scenarios in Supermarket and Grocery stores will be better since they remained open being the essential business. But there are silver linings over the cloud, I also observed that New Zealand retail industry is changing and reshaping their way of doing business due to this pandemic, like the acceleration of digital transformation in Supermarkets. (<em>Detailed data, analysis and insights will be posted on another blog</em>). </p>
<p>I have being paying attentions to New Zealand retail industry, specifically Supermarket and Grocery industry, and recently I drafted a Retail Analytics Framework based on my Retail industry experience in a large Home-Appliance brand company, my understanding of Supermarket business operations, and my data analytics experience. As illustrated in more detail below.</p>
<h1 id="Value-Layer"><a href="#Value-Layer" class="headerlink" title="Value Layer"></a>Value Layer</h1><p>Business value outcomes are realized through improving business operations and better business decision making. The inherent logic is simple, which is the equation below:</p>
<center><b>Profit</b> = <b>Revenue</b> - <b>Cost</b></center>
With increased revenue and reduced cost, business becomes more profitable, which empower the business to achieve more positive outcomes on Customer, Employee, Community, and Environment, etc.

<p>Value layer also generate the business priorities at strategic level, this priorities will then pass down to Operations layer to generate more specific business problem statement and objectives.</p>
<p><img src="/images/retail_analytics_framework_value_layer.png" alt="Value Layer"></p>
<h1 id="Operations-Layer"><a href="#Operations-Layer" class="headerlink" title="Operations Layer"></a>Operations Layer</h1><p>In my opinion, the Supermarket and Grocery stores is actually a B2C platform that brings the products and goods from Suppliers to Customers with their Logistics, Distribution network, and Store branches. The demand generated from Customer transfer through Supermarkets to Suppliers, and supply manufactured by Supplier transfer back through Supermarkets to Customers. For product movement flow, The products are transported from Suppliers to Regional Warehouses, and then transported and distributed to Local store branches. In New Zealand, there are 3 major channels to complete the final step of product movements from Local store branches to Customers:</p>
<ol>
<li>Offline Shopping</li>
<li>Online Shopping &amp; Pick-up</li>
<li>Online Shopping &amp; Delivery</li>
</ol>
<p>The concept here is that every decision making point or operation node in the Operations layer has the potential to be improved/optimized. It is the handle to achieve business value outcomes, and is also the container to embed analytics and insights from the Analytics layer.</p>
<p><img src="/images/retail_analytics_framework_operations_layer.png" alt="Operations Layer"></p>
<h1 id="Analytics-Layer"><a href="#Analytics-Layer" class="headerlink" title="Analytics Layer"></a>Analytics Layer</h1><p>I think the link between Analytics layer and Operations layer is really the most critical step to achieve success in this Analytics Framework, which is the “last-mile” of Analytics. The insights generated from Analytics layer have to be embeded into Operations in different kinds of forms, and the insights must become part of the business operations or have informed decision making so that the 2 layers are not disconnected. This “last-mile” issue is often the failure reason in turning data into business values through analytics.</p>
<p>From my experience, there are 2 key parts in addressing the analytics “last-mile” issue and make it more likely to work:</p>
<ul>
<li>Bussiness problem driven and clear problem definition</li>
<li>Cross training and understanding between business operations team and analytics team</li>
</ul>
<p>Problem driven and clear definition gives Operations and Analytics team a tangible container to take the insights. Through the cross training and understanding, Analytics team understand better about what Operations team want, and Operations team can appreciate more how Analytics could help them. Then Analytics team could package the analytic model and insights into a user/operation-friendly product to be used by Operations team in their daily practice. This often require some design-thinking nowadays.</p>
<p>The framework lists some major topics in Analytics layer for Retail industry, like Customer Analytics, Marketing Analytics, Store Operations Analytics, Supply Chain Analytics, etc. These topics are the common business problem themes in Retail operations and has been discussed many times within industry.</p>
<p><img src="/images/retail_analytics_framework_analytics_layer.png" alt="Analytics Layer"></p>
<h1 id="Data-Layer"><a href="#Data-Layer" class="headerlink" title="Data Layer"></a>Data Layer</h1><p>Data is the food source for Analytics engine. The integration of data sources in Data Warehouse, and the readily usable and accessible business entity views in Data Mart ensure Analytics layer can generate insights efficiently. With the “Gabage in, Gabage out” principle, the Data Governance and Quality Control at Data layer ensure the insights generated with good quality.</p>
<p><img src="/images/retail_analytics_framework_data_layer.png" alt="Data Layer"></p>
<p>That is the introduction to Retail Analytics Framework (v1.0). It will never be ideal due to limitation of my experience, hence the version 1.0 here. Feedbacks will be the most welcomed, please feel free to send Emails to <a href="mailto:renxiangyao@gmail.com">me</a> and share your thoughts.</p>
<p>Next, I plan to write a blog about NZ retail industry and specifically Supermarket industry historical data and recent trend over COVID-19 period. There could be some interesting insights there, so stay tuned! </p>
]]></content>
      <categories>
        <category>Analytics Framework &amp; Roadmap</category>
      </categories>
      <tags>
        <tag>Analytics Framework</tag>
        <tag>Supermarket &amp; Grocery Industry</tag>
        <tag>Retail</tag>
      </tags>
  </entry>
</search>
